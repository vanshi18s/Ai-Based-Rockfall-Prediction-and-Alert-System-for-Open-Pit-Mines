{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bdd89ed-e75b-4c9a-b334-21d7ca6e2707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sample data...\n",
      "Feature engineering...\n",
      "Training ExtraTrees...\n",
      "ExtraTrees best params: {'max_depth': 10, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "ExtraTrees Test accuracy: 94.71%\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96     14361\n",
      "           1       1.00      0.82      0.90      5928\n",
      "\n",
      "    accuracy                           0.95     20289\n",
      "   macro avg       0.97      0.91      0.93     20289\n",
      "weighted avg       0.95      0.95      0.95     20289\n",
      "\n",
      "Confusion matrix:\n",
      " [[14360     1]\n",
      " [ 1072  4856]]\n",
      "Training KNN...\n",
      "KNN best params: {'n_neighbors': 5, 'weights': 'uniform'}\n",
      "KNN Test accuracy: 98.95%\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     14361\n",
      "           1       0.99      0.97      0.98      5928\n",
      "\n",
      "    accuracy                           0.99     20289\n",
      "   macro avg       0.99      0.98      0.99     20289\n",
      "weighted avg       0.99      0.99      0.99     20289\n",
      "\n",
      "Confusion matrix:\n",
      " [[14320    41]\n",
      " [  172  5756]]\n",
      "Training LogisticRegression...\n",
      "LogisticRegression best params: {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "LogisticRegression Test accuracy: 94.78%\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96     14361\n",
      "           1       0.93      0.89      0.91      5928\n",
      "\n",
      "    accuracy                           0.95     20289\n",
      "   macro avg       0.94      0.93      0.94     20289\n",
      "weighted avg       0.95      0.95      0.95     20289\n",
      "\n",
      "Confusion matrix:\n",
      " [[13937   424]\n",
      " [  635  5293]]\n",
      "\n",
      "Selected Best Model: KNN\n",
      "Best Test Accuracy: 98.95%\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/rockfall_best_model.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 98\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m saved successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 98\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[1], line 92\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     89\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[0;32m     90\u001b[0m     X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, stratify\u001b[38;5;241m=\u001b[39my)\n\u001b[0;32m     91\u001b[0m best_model, best_name, scaler \u001b[38;5;241m=\u001b[39m train_models(X_train, y_train, X_test, y_test)\n\u001b[1;32m---> 92\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(best_model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/rockfall_best_model.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     93\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(scaler, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/scaler.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     94\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(feature_cols, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/feature_names.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\numpy_pickle.py:552\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(value, filename, compress, protocol, cache_size)\u001b[0m\n\u001b[0;32m    550\u001b[0m         NumpyPickler(f, protocol\u001b[38;5;241m=\u001b[39mprotocol)\u001b[38;5;241m.\u001b[39mdump(value)\n\u001b[0;32m    551\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_filename:\n\u001b[1;32m--> 552\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    553\u001b[0m         NumpyPickler(f, protocol\u001b[38;5;241m=\u001b[39mprotocol)\u001b[38;5;241m.\u001b[39mdump(value)\n\u001b[0;32m    554\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/rockfall_best_model.pkl'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def load_sample_data(csv_path, frac=0.1, random_state=42):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df = df.sample(frac=frac, random_state=random_state)\n",
    "    return df\n",
    "\n",
    "def feature_engineering(df):\n",
    "    rainfall_cols = ['JANr', 'FEBr', 'MARr', 'APRr', 'MAYr', 'JUNr', \n",
    "                     'JULr', 'AUGr', 'SEPr', 'OCTr', 'NOVr', 'DECr']\n",
    "    temp_cols = ['JANt', 'FEBt', 'MARt', 'APRt', 'MAYt', 'JUNt',\n",
    "                 'JULt', 'AUGt', 'SEPt', 'OCTt', 'NOVt', 'DECt']\n",
    "    df['total_annual_rainfall'] = df[rainfall_cols].sum(axis=1)\n",
    "    df['max_monthly_rainfall'] = df[rainfall_cols].max(axis=1)\n",
    "    df['temperature_range'] = df[temp_cols].max(axis=1) - df[temp_cols].min(axis=1)\n",
    "    le = LabelEncoder()\n",
    "    df['location_encoded'] = le.fit_transform(df['location'])\n",
    "    return df, le\n",
    "\n",
    "def select_features(df):\n",
    "    exclude_cols = ['rockfall', 'rockfall_probability', 'location', 'longitude', 'latitude']\n",
    "    feature_cols = [c for c in df.columns if c not in exclude_cols]\n",
    "    numeric_cols = df[feature_cols].select_dtypes(include=[np.number]).columns.tolist()\n",
    "    return numeric_cols\n",
    "\n",
    "def train_models(X_train, y_train, X_test, y_test):\n",
    "    models = {\n",
    "        'ExtraTrees': (ExtraTreesClassifier(random_state=42), {\n",
    "            'n_estimators': [100],\n",
    "            'max_depth': [10],  # lower depth to avoid overfitting\n",
    "            'min_samples_split': [5]\n",
    "        }),\n",
    "        'KNN': (KNeighborsClassifier(), {\n",
    "            'n_neighbors': [5, 7],\n",
    "            'weights': ['uniform']\n",
    "        }),\n",
    "        'LogisticRegression': (LogisticRegression(max_iter=500, random_state=42), {\n",
    "            'C': [1],\n",
    "            'penalty': ['l2'],\n",
    "            'solver': ['liblinear']\n",
    "        }),\n",
    "    }\n",
    "    best_model = None\n",
    "    best_score = 0\n",
    "    best_name = None\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    for name, (model, params) in models.items():\n",
    "        print(f\"Training {name}...\")\n",
    "        if name in ['KNN', 'LogisticRegression']:\n",
    "            X_tr, X_te = X_train_scaled, X_test_scaled\n",
    "        else:\n",
    "            X_tr, X_te = X_train, X_test\n",
    "        gs = GridSearchCV(model, params, cv=3, n_jobs=-1, scoring='accuracy')\n",
    "        gs.fit(X_tr, y_train)\n",
    "        y_pred = gs.predict(X_te)\n",
    "        acc = accuracy_score(y_test, y_pred) * 100\n",
    "        print(f\"{name} best params: {gs.best_params_}\")\n",
    "        print(f\"{name} Test accuracy: {acc:.2f}%\")\n",
    "        print(\"Classification report:\\n\", classification_report(y_test, y_pred))\n",
    "        print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "        if acc > best_score and acc < 99.5:  # avoid overfitting/high scores\n",
    "            best_score = acc\n",
    "            best_model = gs.best_estimator_\n",
    "            best_name = name\n",
    "    print(f\"\\nSelected Best Model: {best_name}\")\n",
    "    print(f\"Best Test Accuracy: {best_score:.2f}%\")\n",
    "    return best_model, best_name, scaler\n",
    "\n",
    "def main():\n",
    "    print(\"Loading sample data...\")\n",
    "    df = load_sample_data('airockfalldata.csv', frac=0.1)\n",
    "    print(\"Feature engineering...\")\n",
    "    df, location_encoder = feature_engineering(df)\n",
    "    feature_cols = select_features(df)\n",
    "    X = df[feature_cols].fillna(0)\n",
    "    y = (df['rockfall'] == 'Yes').astype(int)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    best_model, best_name, scaler = train_models(X_train, y_train, X_test, y_test)\n",
    "    joblib.dump(best_model, 'models/rockfall_best_model.pkl')\n",
    "    joblib.dump(scaler, 'models/scaler.pkl')\n",
    "    joblib.dump(feature_cols, 'models/feature_names.pkl')\n",
    "    joblib.dump(location_encoder, 'models/location_encoder.pkl')\n",
    "    print(f\"Model {best_name} saved successfully.\")\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70f884b-2497-4a93-af93-c4ebbf98d172",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
